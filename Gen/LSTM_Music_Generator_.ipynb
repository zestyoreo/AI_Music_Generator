{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Music Generator .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install music21"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdZT0pIkr7wS",
        "outputId": "0f09c130-2fb8-47b2-cee4-22d23e013586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: music21 in /usr/local/lib/python3.7/dist-packages (5.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-a2hWQosEOv",
        "outputId": "da8bdaa4-4d48-41a0-80f1-613e00b05d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIhZzNJDxQmw",
        "outputId": "74ae6d51-1cf3-46eb-af3a-367910ff93fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 15 20:38:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     8W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pickle\n",
        "import numpy\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXUFd3LFC7Wv",
        "outputId": "c91d354a-cd37-440c-838a-50c3b1a427d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"/content/drive/MyDrive/Gen/music_data/*.mid\"):\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse() \n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    with open('/content/drive/MyDrive/Gen/data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes"
      ],
      "metadata": {
        "id": "U3uCktfVDEfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = tf.keras.utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)\n"
      ],
      "metadata": {
        "id": "RtwQqnv5DJ-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab,file_name='',ifload=False):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(tf.keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(tf.keras.layers.LSTM(512))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(n_vocab))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    if ifload==True:\n",
        "      model.load_weights(file_name)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GYO4NmHBDT4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, network_input, network_output):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = \"/content/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "fC8I4-vnDdZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3rpQxsWrx5e"
      },
      "outputs": [],
      "source": [
        "def train_network():\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "    print(n_vocab)\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_network()"
      ],
      "metadata": {
        "id": "-H4lpUk8DeH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "17NhtPpvENh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def continue_training(file_name):\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab,file_name,True)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "metadata": {
        "id": "V66XChMSENfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continue_training('/content/drive/MyDrive/Gen/weights-improvement-33-1.3434-bigger.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BzzmIyGwENdH",
        "outputId": "6340431d-b3ca-4e36-da31-8b9f5ee38e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing /content/drive/MyDrive/Gen/music_data/0.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/1.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/2.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/4.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/3.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/5.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/7.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/6.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/10.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/12.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/11.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/8.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/13.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/9.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/14.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/15.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/17.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/16.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/20.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/21.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/19.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/18.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/23.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/22.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/24.mid\n",
            "Parsing /content/drive/MyDrive/Gen/music_data/25.mid\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/200\n",
            "126/126 [==============================] - 102s 759ms/step - loss: 1.3611\n",
            "Epoch 2/200\n",
            "126/126 [==============================] - 96s 760ms/step - loss: 1.2362\n",
            "Epoch 3/200\n",
            "126/126 [==============================] - 99s 786ms/step - loss: 1.1845\n",
            "Epoch 4/200\n",
            "126/126 [==============================] - 97s 766ms/step - loss: 1.1199\n",
            "Epoch 5/200\n",
            "126/126 [==============================] - 97s 771ms/step - loss: 1.0746\n",
            "Epoch 6/200\n",
            "126/126 [==============================] - 95s 753ms/step - loss: 1.0313\n",
            "Epoch 7/200\n",
            "126/126 [==============================] - 97s 773ms/step - loss: 0.9714\n",
            "Epoch 8/200\n",
            "126/126 [==============================] - 95s 755ms/step - loss: 0.9369\n",
            "Epoch 9/200\n",
            "126/126 [==============================] - 96s 764ms/step - loss: 0.9012\n",
            "Epoch 10/200\n",
            "126/126 [==============================] - 94s 747ms/step - loss: 0.8524\n",
            "Epoch 11/200\n",
            "126/126 [==============================] - 97s 766ms/step - loss: 0.8227\n",
            "Epoch 12/200\n",
            "126/126 [==============================] - 95s 751ms/step - loss: 0.7778\n",
            "Epoch 13/200\n",
            "126/126 [==============================] - 89s 702ms/step - loss: 0.7451\n",
            "Epoch 14/200\n",
            "126/126 [==============================] - 88s 702ms/step - loss: 0.7068\n",
            "Epoch 15/200\n",
            "126/126 [==============================] - 90s 714ms/step - loss: 0.6847\n",
            "Epoch 16/200\n",
            "126/126 [==============================] - 95s 756ms/step - loss: 0.6482\n",
            "Epoch 17/200\n",
            "126/126 [==============================] - 93s 738ms/step - loss: 0.6227\n",
            "Epoch 18/200\n",
            "126/126 [==============================] - 95s 757ms/step - loss: 0.5916\n",
            "Epoch 19/200\n",
            "126/126 [==============================] - 93s 739ms/step - loss: 0.5635\n",
            "Epoch 20/200\n",
            "126/126 [==============================] - 95s 755ms/step - loss: 0.5554\n",
            "Epoch 21/200\n",
            "126/126 [==============================] - 93s 739ms/step - loss: 0.5132\n",
            "Epoch 22/200\n",
            "126/126 [==============================] - 95s 754ms/step - loss: 0.4997\n",
            "Epoch 23/200\n",
            "126/126 [==============================] - 94s 747ms/step - loss: 0.4779\n",
            "Epoch 24/200\n",
            "126/126 [==============================] - 95s 756ms/step - loss: 0.4498\n",
            "Epoch 25/200\n",
            "126/126 [==============================] - 94s 745ms/step - loss: 0.4331\n",
            "Epoch 26/200\n",
            "126/126 [==============================] - 96s 760ms/step - loss: 0.4066\n",
            "Epoch 27/200\n",
            "126/126 [==============================] - 93s 742ms/step - loss: 0.4068\n",
            "Epoch 28/200\n",
            "126/126 [==============================] - 95s 755ms/step - loss: 0.3802\n",
            "Epoch 29/200\n",
            "126/126 [==============================] - 94s 744ms/step - loss: 0.3686\n",
            "Epoch 30/200\n",
            "126/126 [==============================] - 96s 764ms/step - loss: 0.3576\n",
            "Epoch 31/200\n",
            "126/126 [==============================] - 94s 742ms/step - loss: 0.3412\n",
            "Epoch 32/200\n",
            "126/126 [==============================] - 95s 755ms/step - loss: 0.3268\n",
            "Epoch 33/200\n",
            "126/126 [==============================] - 95s 747ms/step - loss: 0.3176\n",
            "Epoch 34/200\n",
            "126/126 [==============================] - 93s 741ms/step - loss: 0.3066\n",
            "Epoch 35/200\n",
            "126/126 [==============================] - 96s 759ms/step - loss: 0.2913\n",
            "Epoch 36/200\n",
            "126/126 [==============================] - 93s 741ms/step - loss: 0.2815\n",
            "Epoch 37/200\n",
            "126/126 [==============================] - 95s 758ms/step - loss: 0.2752\n",
            "Epoch 38/200\n",
            "126/126 [==============================] - 93s 741ms/step - loss: 0.2649\n",
            "Epoch 39/200\n",
            "126/126 [==============================] - 95s 752ms/step - loss: 0.2529\n",
            "Epoch 40/200\n",
            "126/126 [==============================] - 94s 742ms/step - loss: 0.2508\n",
            "Epoch 41/200\n",
            "126/126 [==============================] - 96s 758ms/step - loss: 0.2393\n",
            "Epoch 42/200\n",
            "126/126 [==============================] - 93s 738ms/step - loss: 0.2413\n",
            "Epoch 43/200\n",
            "126/126 [==============================] - 95s 753ms/step - loss: 0.2294\n",
            "Epoch 44/200\n",
            "126/126 [==============================] - 93s 740ms/step - loss: 0.2230\n",
            "Epoch 45/200\n",
            "126/126 [==============================] - 95s 752ms/step - loss: 0.2233\n",
            "Epoch 46/200\n",
            "126/126 [==============================] - 92s 733ms/step - loss: 0.2071\n",
            "Epoch 47/200\n",
            "126/126 [==============================] - 94s 749ms/step - loss: 0.2015\n",
            "Epoch 48/200\n",
            "126/126 [==============================] - 92s 731ms/step - loss: 0.2027\n",
            "Epoch 49/200\n",
            "126/126 [==============================] - 94s 744ms/step - loss: 0.1954\n",
            "Epoch 50/200\n",
            "126/126 [==============================] - 91s 720ms/step - loss: 0.1893\n",
            "Epoch 51/200\n",
            "126/126 [==============================] - 87s 692ms/step - loss: 0.1825\n",
            "Epoch 52/200\n",
            "126/126 [==============================] - 85s 678ms/step - loss: 0.1765\n",
            "Epoch 53/200\n",
            "126/126 [==============================] - 87s 694ms/step - loss: 0.1761\n",
            "Epoch 54/200\n",
            "126/126 [==============================] - 85s 672ms/step - loss: 0.1714\n",
            "Epoch 55/200\n",
            "126/126 [==============================] - 87s 692ms/step - loss: 0.1629\n",
            "Epoch 56/200\n",
            "126/126 [==============================] - 84s 670ms/step - loss: 0.1631\n",
            "Epoch 57/200\n",
            "126/126 [==============================] - 87s 690ms/step - loss: 0.1578\n",
            "Epoch 58/200\n",
            "126/126 [==============================] - 85s 676ms/step - loss: 0.1484\n",
            "Epoch 59/200\n",
            "126/126 [==============================] - 86s 683ms/step - loss: 0.1463\n",
            "Epoch 60/200\n",
            "126/126 [==============================] - 85s 670ms/step - loss: 0.1372\n",
            "Epoch 61/200\n",
            "126/126 [==============================] - 86s 679ms/step - loss: 0.1389\n",
            "Epoch 62/200\n",
            "126/126 [==============================] - 84s 667ms/step - loss: 0.1449\n",
            "Epoch 63/200\n",
            "126/126 [==============================] - 86s 684ms/step - loss: 0.1439\n",
            "Epoch 64/200\n",
            "126/126 [==============================] - 84s 665ms/step - loss: 0.1382\n",
            "Epoch 65/200\n",
            "126/126 [==============================] - 85s 678ms/step - loss: 0.1394\n",
            "Epoch 66/200\n",
            "126/126 [==============================] - 84s 666ms/step - loss: 0.1342\n",
            "Epoch 67/200\n",
            "126/126 [==============================] - 84s 668ms/step - loss: 0.1313\n",
            "Epoch 68/200\n",
            "126/126 [==============================] - 85s 676ms/step - loss: 0.1280\n",
            "Epoch 69/200\n",
            "126/126 [==============================] - 83s 662ms/step - loss: 0.1216\n",
            "Epoch 70/200\n",
            "126/126 [==============================] - 85s 677ms/step - loss: 0.1217\n",
            "Epoch 71/200\n",
            "126/126 [==============================] - 83s 661ms/step - loss: 0.1207\n",
            "Epoch 72/200\n",
            "126/126 [==============================] - 86s 683ms/step - loss: 0.1149\n",
            "Epoch 73/200\n",
            "126/126 [==============================] - 84s 670ms/step - loss: 0.1244\n",
            "Epoch 74/200\n",
            "126/126 [==============================] - 85s 674ms/step - loss: 0.1159\n",
            "Epoch 75/200\n",
            "126/126 [==============================] - 84s 668ms/step - loss: 0.1075\n",
            "Epoch 76/200\n",
            "126/126 [==============================] - 86s 682ms/step - loss: 0.1047\n",
            "Epoch 77/200\n",
            "126/126 [==============================] - 83s 660ms/step - loss: 0.1103\n",
            "Epoch 78/200\n",
            "126/126 [==============================] - 85s 675ms/step - loss: 0.1144\n",
            "Epoch 79/200\n",
            "126/126 [==============================] - 83s 662ms/step - loss: 0.1049\n",
            "Epoch 80/200\n",
            "126/126 [==============================] - 85s 677ms/step - loss: 0.1075\n",
            "Epoch 81/200\n",
            "126/126 [==============================] - 84s 666ms/step - loss: 0.0991\n",
            "Epoch 82/200\n",
            "126/126 [==============================] - 86s 681ms/step - loss: 0.1076\n",
            "Epoch 83/200\n",
            "126/126 [==============================] - 84s 666ms/step - loss: 0.1020\n",
            "Epoch 84/200\n",
            "126/126 [==============================] - 85s 675ms/step - loss: 0.0960\n",
            "Epoch 85/200\n",
            "126/126 [==============================] - 84s 665ms/step - loss: 0.0900\n",
            "Epoch 86/200\n",
            "126/126 [==============================] - 86s 681ms/step - loss: 0.0879\n",
            "Epoch 87/200\n",
            "126/126 [==============================] - 84s 665ms/step - loss: 0.0913\n",
            "Epoch 88/200\n",
            "126/126 [==============================] - 86s 681ms/step - loss: 0.0926\n",
            "Epoch 89/200\n",
            "126/126 [==============================] - 83s 661ms/step - loss: 0.0858\n",
            "Epoch 90/200\n",
            "126/126 [==============================] - 85s 675ms/step - loss: 0.0869\n",
            "Epoch 91/200\n",
            "126/126 [==============================] - 84s 664ms/step - loss: 0.0852\n",
            "Epoch 92/200\n",
            "126/126 [==============================] - 86s 680ms/step - loss: 0.0892\n",
            "Epoch 93/200\n",
            "126/126 [==============================] - 83s 660ms/step - loss: 0.0838\n",
            "Epoch 94/200\n",
            "126/126 [==============================] - 86s 682ms/step - loss: 0.0833\n",
            "Epoch 95/200\n",
            "126/126 [==============================] - 84s 664ms/step - loss: 0.0821\n",
            "Epoch 96/200\n",
            "126/126 [==============================] - 83s 658ms/step - loss: 0.0823\n",
            "Epoch 97/200\n",
            "126/126 [==============================] - 85s 676ms/step - loss: 0.0820\n",
            "Epoch 98/200\n",
            "126/126 [==============================] - 85s 671ms/step - loss: 0.0781\n",
            "Epoch 99/200\n",
            "126/126 [==============================] - 85s 677ms/step - loss: 0.0809\n",
            "Epoch 100/200\n",
            "126/126 [==============================] - 83s 662ms/step - loss: 0.0778\n",
            "Epoch 101/200\n",
            "126/126 [==============================] - 86s 679ms/step - loss: 0.0757\n",
            "Epoch 102/200\n",
            "126/126 [==============================] - 83s 663ms/step - loss: 0.0816\n",
            "Epoch 103/200\n",
            "126/126 [==============================] - 86s 682ms/step - loss: 0.0689\n",
            "Epoch 104/200\n",
            "126/126 [==============================] - 83s 660ms/step - loss: 0.0757\n",
            "Epoch 105/200\n",
            "126/126 [==============================] - 86s 683ms/step - loss: 0.0709\n",
            "Epoch 106/200\n",
            "126/126 [==============================] - 83s 662ms/step - loss: 0.0745\n",
            "Epoch 107/200\n",
            "126/126 [==============================] - 86s 679ms/step - loss: 0.0698\n",
            "Epoch 108/200\n",
            "126/126 [==============================] - 85s 673ms/step - loss: 0.0681\n",
            "Epoch 109/200\n",
            "126/126 [==============================] - 85s 678ms/step - loss: 0.0718\n",
            "Epoch 110/200\n",
            "126/126 [==============================] - 85s 673ms/step - loss: 0.0721\n",
            "Epoch 111/200\n",
            "126/126 [==============================] - 85s 676ms/step - loss: 0.0687\n",
            "Epoch 112/200\n",
            "126/126 [==============================] - 85s 673ms/step - loss: 0.0678\n",
            "Epoch 113/200\n",
            "126/126 [==============================] - 86s 681ms/step - loss: 0.0733\n",
            "Epoch 114/200\n",
            "110/126 [=========================>....] - ETA: 10s - loss: 0.0688"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-dafe01107770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Gen/weights-improvement-33-1.3434-bigger.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-1d24cf033bdf>\u001b[0m in \u001b[0;36mcontinue_training\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-b654f5017fad>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, network_input, network_output)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cr2D6yK3ENaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dOXbF0jrENXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Music"
      ],
      "metadata": {
        "id": "A1z5KUq8EFoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    # map between notes and integers and back\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 100\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)\n"
      ],
      "metadata": {
        "id": "C2Z50W6lEUGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def a_create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(tf.keras.layers.LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(tf.keras.layers.LSTM(512))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(n_vocab))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    # Load the weights to each node\n",
        "    model.load_weights('/content/drive/MyDrive/Gen/weights-improvement-103-0.0689-bigger.hdf5')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "u2ZdiCNiEaLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output"
      ],
      "metadata": {
        "id": "fdivXNcAEdfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_midi(prediction_output):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp='test_output9.mid')"
      ],
      "metadata": {
        "id": "YJ6tyViMEg_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "    \"\"\" Generate a piano midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    with open('/content/drive/MyDrive/Gen/data/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    model = a_create_network(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)\n"
      ],
      "metadata": {
        "id": "_bCyCrMBs3Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8-iFHT4EkKJ",
        "outputId": "52485b5e-3b9c-4d47-fe79-80dad18b9f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xvoPAZaIGCf4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}